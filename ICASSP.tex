\documentclass{article}
\usepackage{amsmath,amssymb,amsfonts} % for \mathbb and other symbols
\usepackage{bm}                       % for \bm (bold math)
\usepackage{graphicx,hyperref}
\usepackage{cite}
\usepackage{float}
\usepackage{spconf}
\usepackage{amsmath}
\usepackage{bm}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{bm} % if not already included
\newcommand{\vx}{\bm{x}}

% optional shorthand:
\newcommand{\R}{\mathbb{R}}
\newcommand{\vh}{\mathbf{h}}
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\newcommand{\vth}{\bm{\theta}}

\title{A Novel Transfer Learning Approach for Room Impulse Response Estimation Across Geometrically Diverse and Data-Scarce Environments}

\name{Shahab Pasha\textsuperscript{1}, Jiahong Zhao\textsuperscript{2},  Hualin Ren\textsuperscript{3}, Christian Ritz\textsuperscript{3}}
\address{
\textsuperscript{1}University of Western Australia, School of Engineering \\
\textsuperscript{2}University of Southampton, School of Engineering \\
\textsuperscript{3}University of Wollongong, School of Electrical, Computer and Telecommunication Engineering
}

\begin{document}
\ninept
\maketitle

\begin{abstract}
Accurate Room Impulse Response estimation is critical for realistic audio reproduction, robust echo cancellation, and speech dereverberation applications. Traditional methods, such as geometric acoustic simulations or extensive physical measurements, are often computationally expensive and do not generalize easily to rooms with different shapes or acoustic conditions. In this paper, we propose a transfer learning framework for RIR estimation that effectively adapts models trained on data-rich source domains to target domains with limited measurements. Our approach leverages a geometry-aware encoder to extract shape-invariant features and a decoder that enforces echo sparsity and energy decay constraints. Pretraining on the source domain is followed by selective fine-tuning on the target domain to preserve source knowledge while adapting to new room geometries. Experiments demonstrate that transfer learning enables flexible RIR estimation across diverse room geometries and wall materials. Furthermore, we validate the practical utility through a downstream speech dereverberation task, where our method achieves significant improvements in PESQ (3.24 vs. 2.78) and STOI (0.89 vs. 0.79) compared to GAN-based baselines.
\end{abstract}

\begin{keywords}
Room Impulse Response, Transfer Learning, Acoustic Modeling, Deep Learning
\end{keywords}

\section{Introduction}
Room impulse responses (RIRs) characterize how enclosed spaces filter sound. Accurate RIR estimation is critical for applications such as echo cancellation, speech enhancement, and speaker diarisation \cite{dokmanic2015listening}. Traditional approaches rely on either dedicated measurements or geometric-acoustic simulations, both of which become prohibitively expensive when covering diverse room shapes, materials, and source–receiver positions \cite{Carini2021_RIR_OPS}. Learning-based methods enable blind and data-driven RIR estimation, but generalization often degrades when deployment conditions differ from the training environment \cite{Jalmby2023TASLP,Lee2023WASPAA,10715145,10889495}. This motivates transfer learning from data-rich source domains (e.g., rectangular rooms) to data-scarce target domains with minimal supervision.

End-to-end networks require diverse RIR datasets, yet generating and estimating responses across heterogeneous geometries remains difficult. Classical strategies, including low-rank priors \cite{Jalmby2023TASLP} and optimal transport regularization \cite{Sundstrom2024ICASSP}, exploit geometric structure. Physics-informed approaches improve sample efficiency and generalization by embedding wave-propagation constraints \cite{Karakonstantis2024PINN_RIR,9414399}, while optimal transport barycenters provide principled interpolation between RIR families \cite{Pallewela2025OMT_Barycenters}. Collectively, these inductive biases highlight the need for frameworks that generalize across enclosures while remaining data-efficient.

Transfer learning has emerged as a powerful tool in audio processing, enabling models trained on large source domains to adapt to new contexts with limited supervision \cite{5288526,Choi2017Transfer,10096799,Kong2020PANNs,tang2021study,10626683}.

This work focuses on RIR estimation across heterogeneous geometries using few target-domain labels. We propose a transfer learning framework that combines a geometry-aware encoder with a physics-regularized decoder. The encoder extracts shape-invariant features, while the decoder—pre-trained on source data—is adapted using target examples with priors inspired by low-rank structure and transport-based alignment. Temporal dependencies are modeled via a recurrent neural network (RNN), projecting room parameters into a latent sequence that generates the full time-domain RIR sample-by-sample.  

This work makes three key contributions:
\begin{enumerate}
    \item A transfer learning framework for RIR estimation: pretraining on rectangular rooms and transferring knowledge to L-shaped and irregular rooms with varying wall reflection factors.
    \item An efficient fine-tuning protocol that achieves high accuracy with minimal target-domain data, outperforming baseline low-rank methods.
    \item We conduct a comprehensive evaluation on recorded and simulated rectangular, L-shaped, and irregular rooms, showing consistent improvements in log-spectral distance and time-domain error, underscoring the method’s scalability and robustness across diverse geometries.
\end{enumerate}


\section{Problem Setup and Notations} 
\label{sec:problem_setup}
We characterize a 3D acoustic enclosure using the following parameters:
\begin{itemize}
    \item $\bm{\gamma}\in\R^{p}$: geometry parameter vector encoding room shape (e.g., vertex coordinates) and acoustic properties (wall reflection coefficients), where $p$ is the encoding dimension
    \item $\mathbf{s}\in\R^{3}$: 3D position of the sound source
    \item $\mathbf{m}\in\R^{3}$: 3D position of the microphone
\end{itemize}

The continuous-time room impulse response (RIR) is denoted as
\begin{equation} 
h_{\bm{\gamma}}(t;\mathbf{s},\mathbf{m}),
\end{equation} 
where $t$ is time, and this function characterizes how sound propagates from source $\mathbf{s}$ to microphone $\mathbf{m}$ within the room geometry $\bm{\gamma}$. The observed microphone signal is then
\begin{equation} 
x(t) = (h_{\bm{\gamma}} * s)(t) + n(t), 
\end{equation} 
where $s(t)$ is the source signal, $*$ denotes temporal convolution, and $n(t)$ represents additive measurement noise. 

Working in discrete time with sampling rate $f_s$ (Hz), we represent each RIR as a finite-length vector of $T$ samples:
\begin{equation} 
\vh = [h[0], \dots, h[T-1]]^\top \in \R^{T},
\end{equation} 
where $h[t]$ is the RIR amplitude at discrete time index $t$.

To form the network input, we concatenate all room and position parameters:
\begin{equation}
\mathbf{z} = [\bm{\gamma}, \mathbf{s}, \mathbf{m}] \in \R^{p+6},
\end{equation}
yielding a $(p+6)$-dimensional feature vector (3 dimensions each for source and microphone positions).

For transfer learning, we distinguish between two domains:
\begin{itemize}
    \item \textbf{Source domain} $\mathcal{S}$: data-rich environment (e.g., rectangular rooms) with dataset $\mathcal{D}_S = \{(\mathbf{z}_i^S, \vh_i^S)\}_{i=1}^{N_S}$, where $N_S$ is the number of source training examples
    \item \textbf{Target domain} $\mathcal{T}$: data-scarce environment (e.g., L-shaped or irregular rooms) with dataset $\mathcal{D}_T = \{(\mathbf{z}_j^T, \vh_j^T)\}_{j=1}^{N_T}$, where $N_T$ is the number of target training examples
\end{itemize}
Typically, $N_S \gg N_T$, motivating our transfer learning approach. 

\subsection{Acoustic Background} 
For rectangular (shoebox) rooms, physical acoustics theory predicts that the RIR can be modeled as a sparse sum of delayed and attenuated echoes:
\begin{equation} 
h(t) = \sum_{r=0}^{R} a_r \delta(t-\tau_r), 
\end{equation} 
where:
\begin{itemize}
    \item $R$ is the total number of reflections considered
    \item $\delta(\cdot)$ is the Dirac delta function
    \item $\tau_r = \|\mathbf{r}_r - \mathbf{m}\|/c$ is the time delay for the $r$-th reflection, computed from the Euclidean distance between the $r$-th image source position $\mathbf{r}_r$ and microphone $\mathbf{m}$, divided by the speed of sound $c$ (m/s)
    \item $a_r$ is the attenuation coefficient for the $r$-th reflection, determined by propagation distance and cumulative boundary absorption
\end{itemize}
This sparse echo structure, characterized by discrete arrival times and exponentially decaying amplitudes, motivates our physics-informed regularization in Section~\ref{sec:network_losses}.

\section{Neural Network and Physics-Informed Losses} 
\label{sec:network_losses}
We design our RIR predictor using a factorized architecture consisting of two modules:
\begin{equation}
\label{eq:factorization}
\widehat{\vh} = q_{\bm{\psi}}(h_{\bm{\phi}}(\mathbf{z})), \quad \vth = (\bm{\phi}, \bm{\psi}),
\end{equation}
where:
\begin{itemize}
    \item $h_{\bm{\phi}}: \R^{p+6} \to \R^{D}$ is the \textbf{geometry-aware encoder} parameterized by $\bm{\phi}$, which extracts shape-invariant features from input $\mathbf{z}$
    \item $q_{\bm{\psi}}: \R^{D} \to \R^{T}$ is the \textbf{task-specific decoder} parameterized by $\bm{\psi}$, which generates the RIR sequence
    \item $\widehat{\vh} \in \R^T$ is the predicted RIR
    \item $\vth = (\bm{\phi}, \bm{\psi})$ denotes all trainable parameters
    \item $D$ is the latent feature dimension
\end{itemize}

\textbf{Encoder Architecture.}
The input $\mathbf{z} \in \R^{p+6}$ is first projected via a multi-layer perceptron (MLP) into a latent embedding $\mathbf{z}_\text{proj} \in \R^D$. To generate time-varying representations, this embedding is multiplied element-wise with learned temporal basis vectors $\mathbf{b}_t \in \R^D$ for each time step:
\begin{equation}
\mathbf{c}_t = \mathbf{z}_\text{proj} \odot \mathbf{b}_t, \quad t=0,\dots,T-1,
\end{equation}
where:
\begin{itemize}
    \item $\odot$ denotes element-wise (Hadamard) multiplication
    \item $\mathbf{c}_t \in \R^D$ is the time-conditioned feature vector at time step $t$
    \item $\{\mathbf{b}_t\}_{t=0}^{T-1}$ are learnable basis vectors that modulate the geometry embedding temporally
\end{itemize}

\textbf{Decoder Architecture.}
The sequence $\{\mathbf{c}_t\}_{t=0}^{T-1}$ is processed through a two-layer LSTM network to capture long-range temporal dependencies:
\begin{equation}
\widehat{\mathbf{h}} = \text{LSTM}_2(\text{LSTM}_1(\mathbf{c}_{0:T-1})) \mathbf{w}_\text{out},
\end{equation}
where:
\begin{itemize}
    \item $\text{LSTM}_1$ and $\text{LSTM}_2$ are recurrent layers with hidden states of dimension $D$
    \item $\mathbf{c}_{0:T-1}$ denotes the full sequence $\{\mathbf{c}_0, \mathbf{c}_1, \dots, \mathbf{c}_{T-1}\}$
    \item $\mathbf{w}_\text{out} \in \R^{D}$ is a learned linear projection to scalar outputs
\end{itemize}

\textbf{Supervised Losses.} 
We combine time-domain and frequency-domain reconstruction objectives to ensure accurate RIR prediction:
\begin{align}
\mathcal{L}^{\text{time}} &= \frac{1}{N}\sum_{i=1}^N \|\vh_i - \widehat{\vh}_i\|_2^2,\label{eq:loss_time}\\
\mathcal{L}^{\text{lsd}}  &= \frac{1}{N}\sum_{i=1}^N \frac{1}{F}\sum_{f=1}^F \big(\log|H_i(f)|-\log|\widehat{H}_i(f)|\big)^2,\label{eq:loss_lsd}
\end{align}
where:
\begin{itemize}
    \item $N$ is the batch size or total number of training examples
    \item $\|\cdot\|_2$ is the $\ell_2$ (Euclidean) norm
    \item $H_i(f)$ and $\widehat{H}_i(f)$ are the discrete Fourier transforms of the ground-truth RIR $\vh_i$ and predicted RIR $\widehat{\vh}_i$ at frequency bin $f$
    \item $F$ is the number of frequency bins in the Fourier representation
\end{itemize}

\textbf{Physics-Informed Regularization.}
To enforce acoustic plausibility, we introduce two regularization terms based on known RIR properties. First, we compute a smoothed energy envelope:
\begin{equation}
e[t]=\mathrm{MA}\big(|\widehat{h}[t]|^2;K\big)+\varepsilon,
\end{equation}
where:
\begin{itemize}
    \item $\mathrm{MA}(\cdot; K)$ denotes a moving average filter with window size $K$
    \item $|\widehat{h}[t]|^2$ is the instantaneous energy at time $t$
    \item $\varepsilon > 0$ is a small constant for numerical stability
    \item $e[t]$ represents the smoothed energy envelope
\end{itemize}

The \emph{sparsity regularizer} penalizes energy in early samples (before the direct path):
\begin{equation}
\mathcal{R}_{\mathrm{sparse}}
=\lambda_1\Big\|\frac{\widehat{\vh}_{0:T_{\mathrm{early}}-1}}
{\max_{0\le t<T}|\widehat{h}[t]|+\varepsilon}\Big\|_1,
\end{equation}
where:
\begin{itemize}
    \item $\lambda_1 > 0$ is the sparsity regularization weight
    \item $T_{\mathrm{early}}$ is the time index separating early samples from later reflections
    \item $\widehat{\vh}_{0:T_{\mathrm{early}}-1}$ denotes samples $\{\widehat{h}[0], \dots, \widehat{h}[T_{\mathrm{early}}-1]\}$
    \item $\|\cdot\|_1$ is the $\ell_1$ norm (sum of absolute values)
    \item Division by $\max|\widehat{h}[t]| + \varepsilon$ normalizes for scale invariance
\end{itemize}

The \emph{decay regularizer} enforces exponential energy decay in the late reverberation tail:
\begin{equation}
\mathcal{R}_{\mathrm{decay}}
=\lambda_2\sum_{t=T_{\mathrm{early}}+1}^{T-1}
\Big(\mathrm{ReLU}\!\big(\log e[t]-\log e[t-1]+\tfrac{2\rho}{f_s}\big)\Big)^2,
\end{equation}
where:
\begin{itemize}
    \item $\lambda_2 > 0$ is the decay regularization weight
    \item $\rho > 0$ is the expected energy decay rate (dB/s)
    \item $\mathrm{ReLU}(x) = \max(0, x)$ penalizes only violations of monotonic decay
    \item $\log e[t] - \log e[t-1]$ measures the log-energy change between consecutive time steps
    \item $2\rho/f_s$ is the expected decay per sample in log-domain
\end{itemize}

The overall source-domain objective combines all terms:
\begin{equation}
\label{eq:JS}
\mathcal{J}_S(\vth)=\alpha\,\mathcal{L}^{\mathrm{time}}+\beta\,\mathcal{L}^{\mathrm{lsd}}
+\mathcal{R}_{\text{sparse}}+\mathcal{R}_{\text{decay}},
\end{equation}
where $\alpha, \beta > 0$ are weighting hyperparameters balancing time-domain and frequency-domain reconstruction.


\section{Model Architecture and Priors} 
\label{sec:architecture}
As introduced in Eq.~\eqref{eq:factorization}, we factorize the RIR predictor into two components:

\begin{equation}
\widehat{\vh} = q_{\bm{\psi}}\big(h_{\bm{\phi}}(\mathbf{z})\big), \quad 
\vth = (\bm{\phi}, \bm{\psi}),
\end{equation}
where $h_{\bm{\phi}}$ is the \textbf{encoder} (feature extractor) and $q_{\bm{\psi}}$ is the \textbf{decoder} (task head).

\textbf{Geometry-aware prior:} The encoder processes input $\vx=(\bm{\gamma},\mathbf{s},\mathbf{m})$ with optional positional encodings or learned embeddings to capture spatial relationships and room geometry characteristics that generalize across different room shapes.

\textbf{Physics-informed regularization:} The decoder incorporates sparsity constraint $\mathcal{R}_{\text{sparse}}$ and decay constraint $\mathcal{R}_{\text{decay}}$ (defined in Section~\ref{sec:network_losses}), which steer predictions toward acoustically plausible RIRs exhibiting sparse early reflections and exponential energy decay in the reverberation tail.


\subsection{Transfer Learning and Fine-Tuning} 
\label{sec:transfer_learning}
Our two-stage training strategy leverages abundant source-domain data $\mathcal{D}_S$ while efficiently adapting to scarce target-domain samples $\mathcal{D}_T$.

\textbf{Stage 1: Source-domain pretraining.}
We jointly optimize both encoder parameters $\bm{\phi}$ and decoder parameters $\bm{\psi}$ on the source dataset:
\begin{equation} 
\label{eq:pretrain}
(\bm{\phi}^\ast,\bm{\psi}^\ast)=\argmin_{\bm{\phi},\bm{\psi}} \mathcal{J}_S(\bm{\phi},\bm{\psi}),
\end{equation} 
where:
\begin{itemize}
    \item $\mathcal{J}_S$ is the source-domain loss defined in Eq.~\eqref{eq:JS}
    \item $\bm{\phi}^\ast$ denotes the optimal encoder parameters learned from source data
    \item $\bm{\psi}^\ast$ denotes the optimal decoder parameters learned from source data
    \item $\argmin$ finds parameter values that minimize the objective function
\end{itemize}

\textbf{Stage 2: Target-domain fine-tuning.}
To preserve learned geometric features while adapting to new room shapes, we freeze the pretrained encoder $\bm{\phi}^\ast$ (keep it fixed) and fine-tune only the decoder on target data:
\begin{equation} 
\label{eq:finetune}
\bm{\psi}^{\dagger}=\argmin_{\bm{\psi}}\ \mathcal{J}_T(\bm{\phi}^\ast,\bm{\psi}),
\end{equation} 
where:
\begin{itemize}
    \item $\bm{\phi}^\ast$ is held constant (not updated during this stage)
    \item $\bm{\psi}^{\dagger}$ denotes the fine-tuned decoder parameters adapted to target domain
    \item $\mathcal{J}_T$ is the target-domain objective
\end{itemize}

The target-domain objective is:
\begin{equation} 
\label{eq:JT}
\mathcal{J}_T = \alpha\,\mathcal{L}^{\text{time}}_T + \beta\,\mathcal{L}^{\text{lsd}}_T + \mathcal{R}_{\text{sparse}} + \mathcal{R}_{\text{decay}},
\end{equation} 
where:
\begin{itemize}
    \item $\mathcal{L}^{\text{time}}_T$ and $\mathcal{L}^{\text{lsd}}_T$ are reconstruction losses computed on target-domain data $\mathcal{D}_T$ (same functional form as Eqs.~\eqref{eq:loss_time}--\eqref{eq:loss_lsd})
    \item $\mathcal{R}_{\text{sparse}}$ and $\mathcal{R}_{\text{decay}}$ are the same physics-informed regularizers as in the source domain
    \item $\alpha, \beta$ are the same weighting hyperparameters as in Stage 1
\end{itemize}

This selective fine-tuning strategy transfers shape-invariant representations (captured by frozen $\bm{\phi}^\ast$) while adapting the decoder to target-specific acoustic properties such as different wall materials and room geometries.  

\subsection{Neural Network Architecture and Fine-Tuning} 
Table~\ref{tab:combined_fullwidth} details the DeepRIRNet architecture. The model projects the concatenated input $(\bm{\gamma},\mathbf{s},\mathbf{m})$ into a temporal embedding sequence, processes it through two stacked LSTM layers to model temporal dependencies, and produces the final RIR sequence sample-by-sample. 

During fine-tuning (Stage 2 in Section~\ref{sec:transfer_learning}), we freeze the input projection layer and the first LSTM layer (which constitute the encoder $h_{\bm{\phi}}$), thereby preserving the geometric feature representations learned from the source domain. Only the second LSTM layer and output projection (the decoder $q_{\bm{\psi}}$) are updated on target data. Recurrent layers are chosen over feedforward or convolutional architectures because they naturally capture the long-range temporal dependencies and progressive echo decay characteristic of room impulse responses.  

\subsection{Evaluation Metrics}
We quantify RIR estimation performance using three complementary metrics that assess different aspects of prediction quality.

The \emph{Mean Square Error} (MSE) measures time-domain sample-wise accuracy:
\begin{equation}
\mathrm{MSE} = \frac{1}{T}\sum_{t=0}^{T-1} (\widehat{h}[t]-h[t])^2,
\label{eq:mse}
\end{equation}
where $\widehat{h}[t]$ is the predicted RIR sample at time $t$, $h[t]$ is the ground-truth RIR sample, and $T$ is the total number of samples.

The \emph{Log-Spectral Distance} (LSD) captures frequency-domain fidelity:
\begin{equation}
\mathrm{LSD} = \frac{1}{F}\sum_{f=1}^{F} \big(\log|\widehat{H}(f)| - \log|H(f)|\big)^2,
\label{eq:lsd}
\end{equation}
where:
\begin{itemize}
    \item $\widehat{H}(f)$ is the discrete Fourier transform (magnitude spectrum) of the predicted RIR at frequency bin $f$
    \item $H(f)$ is the discrete Fourier transform of the ground-truth RIR at frequency bin $f$
    \item $F$ is the total number of frequency bins
    \item $\log|\cdot|$ denotes the logarithm of the magnitude spectrum
\end{itemize}

Finally, the \emph{Average Time Error} (ATE) provides an $\ell_1$ measure of absolute deviation:
\begin{equation}
\mathrm{ATE} = \frac{1}{T}\sum_{t=0}^{T-1} |\widehat{h}[t]-h[t]|,
\label{eq:ate}
\end{equation}
where $|\cdot|$ denotes the absolute value.

Together, these metrics assess both waveform accuracy (MSE, ATE) and spectral consistency (LSD), providing a comprehensive evaluation of RIR estimation quality.




\begin{table*}[h]
\centering
\caption{Network architecture. Input dimension is $p+6$, where $p$ is the size of the geometry encoding $\gamma$, and the additional 6 dimensions correspond to the 3D source and microphone coordinates.}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Layer / Parameter} & \textbf{Input Dim} & \textbf{Output Dim / Value} & \textbf{Activation / Notes} \\ \hline
\multicolumn{4}{|c|}{\textbf{DeepRIRNet Architecture}} \\ \hline
Input projection & $d=p+6$ & $T\times 256$ & Latent temporal embedding \\ \hline
LSTM (Layer 1) & $T\times 256$ & $T\times 256$ & Hidden=256, dropout=0.0 (frozen) \\ \hline
LSTM (Layer 2) & $T\times 256$ & $T\times 256$ & Hidden=256, dropout=0.2 \\ \hline
Linear (Output) & 256 & 1 & Time-distributed \\ \hline
Reshape & (Batch, $T$, 1) & (Batch, $T$) & Final RIR sequence \\ \hline
\multicolumn{4}{|c|}{\textbf{Fine-Tuning Configuration}} \\ \hline
Frozen & \multicolumn{3}{l|}{Projection + first LSTM} \\ \hline
Trainable & \multicolumn{3}{l|}{Second LSTM + Output Linear} \\ \hline
Optimizer & \multicolumn{3}{l|}{Adam, lr=$1\times10^{-3}$} \\ \hline
Scheduler & \multicolumn{3}{l|}{ReduceLROnPlateau (factor=0.5, patience=10)} \\ \hline
Loss & \multicolumn{3}{l|}{MSE + LSD + Sparsity + Decay} \\ \hline
Epochs & \multicolumn{3}{l|}{50} \\ \hline
Dropout & \multicolumn{3}{l|}{0.2 (second LSTM)} \\ \hline
\end{tabular}
\label{tab:combined_fullwidth}
\end{table*}
\begin{table}[h]
\caption{RIR Dataset and Simulation Details. Each room contributes at least 50 RIRs.}
\label{tab:rir_dataset}
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{lccccc}
\hline
Room Geometry & Num. Rooms & Num. RIRs & RIR Length & Sampling Freq. & Usage \\
\hline
Rectangular & 500 & 25{,}200 & 4096 & 16 kHz & Pretrain \\
L-shaped    & 30  & 1{,}550  & 4096 & 16 kHz & Fine-tune \\
Irregular   & 20  & 1{,}100  & 4096 & 16 kHz & Fine-tune \\
\hline
\end{tabular}
}
\vspace{1mm}
\end{table}

\section{Evaluation and Results} 
\label{sec:evaluation}
We evaluate the proposed framework on both recorded \cite{dicarlo2021dechorate} and simulated RIRs spanning multiple room geometries. The source domain comprises 500 rectangular rooms, while the target domain includes 30 L-shaped and 20 irregular rooms \cite{Pasha2025_inconsistentRIRdataset}. For fine-tuning, we sample a subset of 10 target rooms (5 L-shaped, 5 irregular), reserving the remainder for testing.
 

\subsection{Dataset Construction Protocol} 
To ensure consistency and reproducibility across domains, we adopt a standardized procedure (summarized in Table~\ref{tab:rir_dataset}) that captures both acoustic variability and source–microphone diversity. For each domain $D \in \{\mathcal{S}, \mathcal{T}\}$, we generate RIR samples as follows:
\begin{enumerate}
    \item \textbf{Sample geometry:} Draw a room geometry $\bm{\gamma} \sim p_D(\bm{\gamma})$ from the domain-specific distribution, where $p_D(\cdot)$ is the probability distribution over room geometries in domain $D$. The vector $\gamma$ encodes vertex coordinates defining the room shape and reflection factors for each wall surface (zero-padded as needed to maintain uniform dimension $p$ across all rooms).
    
    \item \textbf{Sample acoustic properties:} For each wall surface in the room, sample reflection coefficients (values between 0 and 1, where 0 = complete absorption, 1 = perfect reflection). Then randomly place the sound source at position $\mathbf{s} = [s_x, s_y, s_z]^\top$ and microphone at position $\mathbf{m} = [m_x, m_y, m_z]^\top$ within the room boundaries.
    
    \item \textbf{Generate RIR:} Either simulate the RIR $h_{\bm{\gamma}}(t;\mathbf{s},\mathbf{m})$ using acoustic modeling (e.g., image-source method) or measure it physically in a real room. Discretize at sampling rate $f_s = 16$ kHz and truncate or zero-pad to obtain fixed-length vector $\vh \in \mathbb{R}^T$ with $T = 4096$ samples.
    
    \item \textbf{Prepare network input:} Construct the input feature vector $\vx = (\bm{\gamma}, \mathbf{s}, \mathbf{m}) \in \R^{p+6}$ by concatenating geometry encoding and spatial positions. Apply z-score normalization (zero mean, unit variance) to each feature dimension. Partition the full dataset into training (70\%), validation (15\%), and test (15\%) splits.
\end{enumerate}


\subsection{Experimental Setup}
The source domain contains 500 rectangular rooms, each contributing at least 50 source–microphone pairs, yielding a total of 25,200 training RIRs. The target domain includes 30 L-shaped and 20 irregular rooms. Fine-tuning employs 10 target rooms (5 L-shaped, 5 irregular), while the remaining target rooms are reserved for evaluation. 

RIRs were either recorded \cite{dicarlo2021dechorate} or generated using the image-source method \cite{Allen1979ImageSource}, then truncated or zero-padded to 4096 samples to ensure uniform input length. Each RIR captures the complete acoustic response, including direct sound, early reflections, and late reverberation, enabling consistent training and evaluation across geometrically diverse environments. The network input $(\bm{\gamma}, \mathbf{s}, \mathbf{m})$ encodes room geometry and source–receiver positions as described in Section~\ref{sec:problem_setup}. 

Figures~\ref{fig:Train_loss}–\ref{fig:fine_tuning_loss} illustrate the training dynamics: source-domain pretraining exhibits stable convergence over epochs, while target-domain fine-tuning achieves rapid adaptation despite limited data.


  

\begin{figure}[htbp]
\centering
\begin{minipage}[t]{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/1.png}
    \vspace{2pt}
    \small (a) Source-domain pretraining loss.
\end{minipage}\hfill
\begin{minipage}[t]{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/2.png}
    \vspace{2pt}
    \small (b) Target-domain fine-tuning loss.
\end{minipage}
\caption{Training dynamics: (a) stable convergence during source pretraining; (b) rapid adaptation during target fine-tuning.}
\label{fig:train_finetune}
\end{figure}



\begin{figure*}[t]
\centering
\includegraphics[width=0.6\textwidth]{figures/6.png}
\caption{Method comparison on L-shaped and irregular rooms. Baselines: GAN-based RIR \cite{Ratnarajah2022GAN_RIR}, low-rank \cite{Jalmby2023TASLP}, and source-only. Results averaged over 3 seeds and 20 test rooms.}
\label{fig:comparison_methods}
\end{figure*}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\linewidth]{figures/4.png}
\caption{LSD vs. wall reflection coefficient (lower is better).}
\label{fig:lsd_absorption}
\end{figure}



\begin{table}[t]
\caption{Evaluation results (mean $\pm$ std, std across test samples, averaged over three seeds). 
LSD computed with STFT: $n_{\text{fft}}=512$, hop length $=128$, window length $=512$ (Hann).}
\label{tab:results}
\centering
\begin{tabular}{lccc}
\hline
Method & MSE & LSD [dB] & ATE \\
\hline
Source-only & $0.0025 \pm 0.0003$ & $3.12 \pm 0.15$ & $8.4 \pm 0.6$ \\
Fine-tuned  & $0.0011 \pm 0.0002$ & $1.95 \pm 0.10$ & $4.2 \pm 0.3$ \\
\hline
\end{tabular}
\end{table}




\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{figures/5.png}
\caption{Fine-tuning strategies: source-only, output-only, and proposed (freeze encoder, adapt decoder). MSE units: $\times 10^{-3}$.}
\label{fig:comparison}
\end{figure}



% Update the text reference in Quantitative Results / Discussion
% (This comment block removed as the discussion is now integrated above)



\subsection{Quantitative Results and Discussion}
Table~\ref{tab:results} summarizes the aggregated performance across three evaluation metrics. Compared to source-only pretraining (no fine-tuning), the proposed fine-tuning strategy reduces MSE (Eq.~\ref{eq:mse}) by $\sim$56\% and LSD (Eq.~\ref{eq:lsd}) by $\sim$37\%, confirming the benefit of transfer learning for adapting to target-domain geometries with limited data.

The results demonstrate that transfer learning from rectangular (source) to L-shaped and irregular (target) rooms significantly improves RIR estimation. The geometry-aware encoder extracts shape-invariant features during pretraining, while the physics-informed decoder (enforcing sparsity and decay) ensures acoustically plausible predictions. Fine-tuning the decoder alone (Eq.~\eqref{eq:finetune}) enables rapid adaptation to target-specific echo patterns (Figure~\ref{fig:comparison}), supporting applications in spatial audio rendering and speech enhancement. 

Figure~\ref{fig:comparison_methods} compares the proposed approach against multiple baselines across 20 test room configurations: a GAN-based generative model \cite{Ratnarajah2022GAN_RIR}, a low-rank estimation method \cite{Jalmby2023TASLP}, and source-only pretraining. The proposed transfer learning method achieves the lowest LSD across most test setups, demonstrating superior spectral fidelity and robustness to geometric variations. The GAN baseline exhibits higher variability and LSD, while the low-rank method shows moderate performance. Figure~\ref{fig:lsd_absorption} further shows that LSD remains stable across a range of wall reflection coefficients (0.2–0.8), indicating robustness to varying absorption properties. These results confirm that the proposed approach maintains superior performance across diverse room geometries and acoustic conditions. 

\subsection{Downstream Application: Speech Dereverberation}

To validate the practical utility of the estimated RIRs, we evaluate their performance in a downstream speech dereverberation task. Accurate RIR estimation enables better inverse filtering and dereverberation, which are critical for applications such as automatic speech recognition (ASR), teleconferencing, and hearing aids.

\textbf{Experimental Protocol:} We generated reverberant speech signals by convolving clean utterances from the TIMIT corpus with both ground-truth RIRs and estimated RIRs from different methods. A Wiener filtering-based dereverberation algorithm \cite{Habets2007Dereverberation} was then applied using each estimated RIR to recover the clean speech. Performance was measured using:
\begin{itemize}
    \item \textbf{PESQ (Perceptual Evaluation of Speech Quality) \cite{Rix2001PESQ}:} A standard perceptual quality metric ranging from 1.0 (poor) to 4.5 (excellent).
    \item \textbf{STOI (Short-Time Objective Intelligibility) \cite{Taal2011STOI}:} Measures speech intelligibility, ranging from 0 to 1.
    \item \textbf{Cepstral Distance (CD):} Lower values indicate better spectral matching to clean speech.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{figures/3.png}
\caption{Dereverberation performance comparison across different RIR estimation methods. Metrics shown: PESQ (higher is better), STOI (higher is better), and Cepstral Distance (lower is better). Results averaged over 50 TIMIT utterances across 10 target room configurations.}
\label{fig:dereverberation}
\end{figure}

\textbf{Results:} As shown in Figure~\ref{fig:dereverberation}, dereverberation using RIRs estimated by the proposed transfer learning method achieves a PESQ score of 3.24 $\pm$ 0.15, significantly outperforming the GAN baseline (2.78 $\pm$ 0.21) and source-only pretraining (2.91 $\pm$ 0.18). Similarly, STOI improves from 0.82 (source-only) and 0.79 (GAN) to 0.89 (proposed), while cepstral distance decreases from 3.8 dB to 2.1 dB. These improvements demonstrate that more accurate RIR estimation directly translates to superior dereverberation quality, validating the practical value of the proposed transfer learning framework for real-world speech processing applications.


\section{Conclusion and Future Work}
In this work, we presented a transfer learning framework for room impulse response estimation across geometrically diverse acoustic environments. By combining a geometry-aware encoder with a physics-informed decoder, the proposed approach effectively transfers knowledge from data-rich rectangular rooms (source domain) to data-scarce L-shaped and irregular rooms (target domain). 

Our two-stage training protocol—pretraining both encoder and decoder on source data (Eq.~\eqref{eq:pretrain}), followed by selective decoder fine-tuning on target data (Eq.~\eqref{eq:finetune})—achieves significant performance gains with minimal target-domain supervision. Experiments on a mixture of simulated and real-world recorded RIRs demonstrate that the method accurately captures echo timing and energy decay across diverse geometries, as evidenced by reductions in MSE, LSD, and ATE metrics. Furthermore, downstream speech dereverberation experiments confirm the practical utility of the estimated RIRs, with substantial improvements in PESQ (3.24 vs. 2.78) and STOI (0.89 vs. 0.79) compared to GAN-based baselines, demonstrating direct translation to real-world speech processing applications.

Future work will explore semi-supervised and unsupervised domain adaptation techniques to further reduce reliance on labeled target data. Additionally, we will investigate alternative layer-freezing strategies to better understand which network components most effectively transfer geometric knowledge versus acoustic-specific features. The implementation of DeepRIRNet, including training and evaluation utilities, is publicly available online \cite{Pasha2025DeepRIRNet}.


\clearpage  
 \bibliographystyle{IEEEtran} \bibliography{references}
\end{document}
